# Atticus AI Provider Configuration
# This file defines all available AI providers, their models, and capabilities
# Format: YAML 1.2
# Last Updated: 2025-10-14

version: "1.1.0"
minAppVersion: "0.9.11"
lastUpdated: "2025-10-14T00:00:00Z"
updateUrl: "https://jdai.ca/atticus/providers.yaml"
license: "Copyright (c) 2025 John Kost, All Rights Reserved."

# AI Provider Templates
# Each provider includes models, capabilities, authentication info, and UI settings
providers:
  # OpenAI - GPT Models
  - id: openai
    name: OpenAI
    displayName: OpenAI
    description: GPT-4o, o1, GPT-4 Turbo, and GPT-3.5 models
    endpoint: https://api.openai.com/v1/chat/completions
    defaultModel: gpt-4o

    models:
      - id: gpt-4o
        name: GPT-4o
        description: Most advanced multimodal model, faster and cheaper than GPT-4 Turbo
        maxContextWindow: 128000
        defaultMaxTokens: 4096
        maxMaxTokens: 16384
        inputTokenPrice: 2.50
        outputTokenPrice: 10.00
        enabled: true

      - id: gpt-4o-mini
        name: GPT-4o mini
        description: Affordable small model for fast, lightweight tasks
        maxContextWindow: 128000
        defaultMaxTokens: 2048
        maxMaxTokens: 8192
        inputTokenPrice: 0.15
        outputTokenPrice: 0.60
        enabled: true

      - id: o1-preview
        name: O1 Preview
        description: Advanced reasoning model, excels at complex problem-solving
        maxContextWindow: 128000
        defaultMaxTokens: 4096
        maxMaxTokens: 32768
        inputTokenPrice: 15.00
        outputTokenPrice: 60.00
        enabled: true

      - id: o1-mini
        name: O1 Mini
        description: Faster reasoning model, great for code and STEM
        maxContextWindow: 128000
        defaultMaxTokens: 2048
        maxMaxTokens: 16384
        inputTokenPrice: 3.00
        outputTokenPrice: 12.00
        enabled: true

      - id: gpt-4-turbo
        name: GPT-4 Turbo
        description: GPT-4 with 128K context, vision capabilities
        maxContextWindow: 128000
        defaultMaxTokens: 4096
        maxMaxTokens: 16384
        inputTokenPrice: 10.00
        outputTokenPrice: 30.00
        enabled: true

      - id: gpt-4-turbo-preview
        name: GPT-4 Turbo Preview
        description: Preview version of GPT-4 Turbo
        maxContextWindow: 128000
        defaultMaxTokens: 4096
        maxMaxTokens: 16384
        inputTokenPrice: 10.00
        outputTokenPrice: 30.00
        enabled: true

      - id: gpt-4
        name: GPT-4
        description: High quality, comprehensive responses (8K context)
        maxContextWindow: 8192
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 30.00
        outputTokenPrice: 60.00
        enabled: true

      - id: gpt-3.5-turbo
        name: GPT-3.5 Turbo
        description: Fast and cost-effective for simple queries
        maxContextWindow: 16385
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 0.50
        outputTokenPrice: 1.50
        enabled: true

    capabilities:
      supportsMultimodal: true
      supportsRAG: true
      supportsVision: true
      supportsFunctionCalling: true

    authentication:
      apiKeyFormat: sk-...
      apiKeyLabel: OpenAI API Key
      getApiKeyUrl: https://platform.openai.com/api-keys

    ui:
      icon: "ü§ñ"
      order: 1

  # Anthropic - Claude Models
  - id: anthropic
    name: Anthropic
    displayName: Anthropic Claude
    description: Claude 4 family - Opus, Sonnet, and Haiku
    endpoint: https://api.anthropic.com/v1/messages
    defaultModel: claude-sonnet-4-5

    models:
      - id: claude-sonnet-4-5
        name: Claude 4.5 Sonnet (Latest)
        description: Most intelligent model, best for complex analysis and coding
        maxContextWindow: 200000
        defaultMaxTokens: 16384
        maxMaxTokens: 64000
        inputTokenPrice: 3.00
        outputTokenPrice: 15.00
        enabled: true

      - id: claude-haiku-4-5
        name: Claude 4.5 Haiku (Latest)
        description: Fastest and most compact model
        maxContextWindow: 200000
        defaultMaxTokens: 16384
        maxMaxTokens: 64000
        inputTokenPrice: 1.00
        outputTokenPrice: 5.00
        enabled: true

      - id: claude-opus-4-1
        name: Claude 4.1 Opus
        description: Powerful model for highly complex tasks
        maxContextWindow: 200000
        defaultMaxTokens: 16384
        maxMaxTokens: 32000
        inputTokenPrice: 15.00
        outputTokenPrice: 75.00
        enabled: true

    capabilities:
      supportsMultimodal: true
      supportsRAG: true
      supportsVision: true
      supportsFunctionCalling: true

    authentication:
      apiKeyFormat: sk-ant-...
      apiKeyLabel: Anthropic API Key
      getApiKeyUrl: https://console.anthropic.com/settings/keys

    ui:
      icon: "üß†"
      order: 2

  # Google - Gemini Models
  - id: google
    name: Google
    displayName: Google Gemini
    description: Gemini 2.5 Pro, Flash, and other Gemini models
    endpoint: https://generativelanguage.googleapis.com/v1beta/openai/
    defaultModel: gemini-2.5-pro

    models:
      - id: gemini-2.5-pro
        name: Gemini 2.5 Pro
        description: Most capable model, 1M token context, multimodal
        maxContextWindow: 1000000
        defaultMaxTokens: 8192
        maxMaxTokens: 8192
        inputTokenPrice: 2.50
        outputTokenPrice: 15.00
        enabled: true

      - id: gemini-2.5-flash
        name: Gemini 2.5 Flash
        description: Fast and efficient, 1M token context, multimodal
        maxContextWindow: 1000000
        defaultMaxTokens: 8192
        maxMaxTokens: 8192
        inputTokenPrice: 0.30
        outputTokenPrice: 2.50
        enabled: true

      - id: gemini-2.5-flash-lite
        name: Gemini 2.5 Flash Lite
        description: Lightweight and cost-effective, 1M token context
        maxContextWindow: 1000000
        defaultMaxTokens: 8192
        maxMaxTokens: 8192
        inputTokenPrice: 0.10
        outputTokenPrice: 0.40
        enabled: true

    capabilities:
      supportsMultimodal: true
      supportsRAG: true
      supportsVision: true
      supportsFunctionCalling: true

    authentication:
      apiKeyFormat: AI...
      apiKeyLabel: Google AI API Key
      getApiKeyUrl: https://makersuite.google.com/app/apikey

    ui:
      icon: "üî∑"
      order: 3

  # Azure OpenAI
  - id: azure-openai
    name: Azure OpenAI
    displayName: Azure OpenAI
    description: GPT-4o, GPT-4o-mini, and GPT-4 via Microsoft Azure
    endpoint: "" # User provides their Azure resource name (e.g., "my-openai-resource"). Full URL is constructed automatically.
    defaultModel: gpt-4o

    models:
      - id: gpt-4o
        name: GPT-4o
        description: GPT-4o via Azure
        maxContextWindow: 128000
        defaultMaxTokens: 4096
        maxMaxTokens: 16384
        inputTokenPrice: 2.50
        outputTokenPrice: 10.00
        enabled: true

      - id: gpt-4o-mini
        name: GPT-4o mini
        description: GPT-4o mini with 128K context via Azure
        maxContextWindow: 128000
        defaultMaxTokens: 2048
        maxMaxTokens: 8192
        inputTokenPrice: 0.15
        outputTokenPrice: 0.60
        enabled: true

      - id: gpt-4
        name: GPT-4
        description: GPT-4 8K via Azure
        maxContextWindow: 8192
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 30.00
        outputTokenPrice: 60.00
        enabled: true

    capabilities:
      supportsMultimodal: true
      supportsRAG: true
      supportsVision: true
      supportsFunctionCalling: true

    authentication:
      apiKeyFormat: "..."
      apiKeyLabel: Azure API Key
      getApiKeyUrl: https://portal.azure.com

    ui:
      icon: "‚òÅÔ∏è"
      order: 4

  # xAI - Grok Models
  - id: xai
    name: xAI
    displayName: xAI Grok
    description: Grok models by xAI (Elon Musk's AI company)
    endpoint: https://api.x.ai/v1/chat/completions
    defaultModel: grok-4

    models:
      - id: grok-4
        name: Grok 4
        description: Latest Grok model with real-time knowledge
        maxContextWindow: 256000
        defaultMaxTokens: 128000
        maxMaxTokens: 256000
        inputTokenPrice: 6.00
        outputTokenPrice: 30.00
        enabled: true

      - id: grok-4-fast-reasoning
        name: Grok 4 Fast Reasoning
        description: Grok with fast reasoning capabilities
        maxContextWindow: 2000000
        defaultMaxTokens: 16384
        maxMaxTokens: 256000
        inputTokenPrice: 0.40
        outputTokenPrice: 1.00
        enabled: true

      - id: grok-4-fast-non-reasoning
        name: Grok 4 Fast Non-Reasoning
        description: Grok with fast non-reasoning capabilities
        maxContextWindow: 2000000
        defaultMaxTokens: 16384
        maxMaxTokens: 256000
        inputTokenPrice: 0.40
        outputTokenPrice: 1.00
        enabled: true

    capabilities:
      supportsMultimodal: true
      supportsRAG: true
      supportsVision: true
      supportsFunctionCalling: false

    authentication:
      apiKeyFormat: xai-...
      apiKeyLabel: xAI API Key
      getApiKeyUrl: https://console.x.ai/

    ui:
      icon: "ùïè"
      order: 5

  # Mistral AI
  - id: mistral
    name: Mistral
    displayName: Mistral AI
    description: Mistral Large 2, Mixtral, and open-source models
    endpoint: https://api.mistral.ai/v1/chat/completions
    defaultModel: mistral-large-latest

    models:
      - id: mistral-large-latest
        name: Mistral Large 2
        description: Most capable model (123B), best for complex reasoning
        maxContextWindow: 128000
        defaultMaxTokens: 4096
        maxMaxTokens: 16384
        inputTokenPrice: 2.00
        outputTokenPrice: 6.00
        enabled: true

      - id: mistral-medium-latest
        name: Mistral Medium
        description: Balanced performance and cost
        maxContextWindow: 32000
        defaultMaxTokens: 2048
        maxMaxTokens: 8192
        inputTokenPrice: 2.70
        outputTokenPrice: 8.10
        enabled: true

      - id: mistral-small-latest
        name: Mistral Small
        description: Fast and cost-effective
        maxContextWindow: 32000
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 0.20
        outputTokenPrice: 0.60
        enabled: true

      - id: open-mixtral-8x22b
        name: Mixtral 8x22B
        description: Powerful mixture-of-experts model
        maxContextWindow: 64000
        defaultMaxTokens: 4096
        maxMaxTokens: 8192
        inputTokenPrice: 2.00
        outputTokenPrice: 6.00
        enabled: true

      - id: open-mixtral-8x7b
        name: Mixtral 8x7B
        description: Efficient mixture-of-experts model
        maxContextWindow: 32768
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 0.70
        outputTokenPrice: 0.70
        enabled: true

    capabilities:
      supportsMultimodal: false
      supportsRAG: true
      supportsFunctionCalling: true

    authentication:
      apiKeyFormat: "..."
      apiKeyLabel: Mistral API Key
      getApiKeyUrl: https://console.mistral.ai/api-keys/

    ui:
      icon: "üå¨Ô∏è"
      order: 6

  # Cohere
  - id: cohere
    name: Cohere
    displayName: Cohere
    description: Enterprise-grade Command models for complex reasoning
    endpoint: https://api.cohere.ai/v1/chat
    defaultModel: command-r-plus

    models:
      - id: command-r-plus
        name: Command R+
        description: Most capable, 128k context, best for complex legal analysis
        maxContextWindow: 128000
        defaultMaxTokens: 4096
        maxMaxTokens: 16384
        inputTokenPrice: 3.00
        outputTokenPrice: 15.00
        enabled: true

      - id: command-r
        name: Command R
        description: Balanced performance and cost, 128k context
        maxContextWindow: 128000
        defaultMaxTokens: 4096
        maxMaxTokens: 8192
        inputTokenPrice: 0.50
        outputTokenPrice: 1.50
        enabled: true

      - id: command
        name: Command
        description: Fast and cost-effective for simpler tasks
        maxContextWindow: 4096
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 1.00
        outputTokenPrice: 2.00
        enabled: true

      - id: command-light
        name: Command Light
        description: Fastest, most economical option
        maxContextWindow: 4096
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 0.30
        outputTokenPrice: 0.60
        enabled: true

    capabilities:
      supportsMultimodal: false
      supportsRAG: true
      supportsFunctionCalling: true

    authentication:
      apiKeyFormat: "..."
      apiKeyLabel: Cohere API Key
      getApiKeyUrl: https://dashboard.cohere.com/api-keys

    ui:
      icon: "üß¨"
      order: 7

  # Groq - Ultra-fast inference
  - id: groq
    name: Groq
    displayName: Groq
    description: Ultra-fast inference with Llama 3.3, Llama 3.1, Mixtral, and Gemma
    endpoint: https://api.groq.com/openai/v1/chat/completions
    defaultModel: llama-3.3-70b-versatile

    models:
      - id: llama-3.3-70b-versatile
        name: Llama 3.3 70B
        description: Latest and most capable Llama model, excellent reasoning
        maxContextWindow: 131072
        defaultMaxTokens: 8192
        maxMaxTokens: 32768
        inputTokenPrice: 0.59
        outputTokenPrice: 0.79
        enabled: true

      - id: llama-3.1-70b-versatile
        name: Llama 3.1 70B
        description: Previous generation, excellent reasoning and analysis
        maxContextWindow: 131072
        defaultMaxTokens: 8192
        maxMaxTokens: 32768
        inputTokenPrice: 0.59
        outputTokenPrice: 0.79
        enabled: true

      - id: llama-3.1-8b-instant
        name: Llama 3.1 8B
        description: Fast and efficient for quick responses
        maxContextWindow: 131072
        defaultMaxTokens: 2048
        maxMaxTokens: 8192
        inputTokenPrice: 0.05
        outputTokenPrice: 0.08
        enabled: true

      - id: mixtral-8x7b-32768
        name: Mixtral 8x7B
        description: Mixture-of-experts, great for diverse tasks
        maxContextWindow: 32768
        defaultMaxTokens: 2048
        maxMaxTokens: 8192
        inputTokenPrice: 0.24
        outputTokenPrice: 0.24
        enabled: true

      - id: gemma2-9b-it
        name: Gemma 2 9B
        description: Efficient and capable Google model
        maxContextWindow: 8192
        defaultMaxTokens: 2048
        maxMaxTokens: 8192
        inputTokenPrice: 0.20
        outputTokenPrice: 0.20
        enabled: true

    capabilities:
      supportsMultimodal: false
      supportsRAG: true
      supportsFunctionCalling: true

    authentication:
      apiKeyFormat: gsk_...
      apiKeyLabel: Groq API Key
      getApiKeyUrl: https://console.groq.com/keys

    ui:
      icon: "‚ö°"
      order: 8

  # Perplexity AI
  - id: perplexity
    name: Perplexity
    displayName: Perplexity AI
    description: Real-time web search and citations for legal research
    endpoint: https://api.perplexity.ai/chat/completions
    defaultModel: llama-3.1-sonar-large-128k-online

    models:
      - id: llama-3.1-sonar-large-128k-online
        name: Sonar Large (Online)
        description: Most capable with real-time web search and citations
        maxContextWindow: 127072
        defaultMaxTokens: 4096
        maxMaxTokens: 8192
        inputTokenPrice: 1.00
        outputTokenPrice: 1.00
        enabled: true

      - id: llama-3.1-sonar-small-128k-online
        name: Sonar Small (Online)
        description: Fast web search with citations, cost-effective
        maxContextWindow: 127072
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 0.20
        outputTokenPrice: 0.20
        enabled: true

      - id: llama-3.1-sonar-large-128k-chat
        name: Sonar Large (Chat)
        description: Offline reasoning, no web search
        maxContextWindow: 127072
        defaultMaxTokens: 4096
        maxMaxTokens: 8192
        inputTokenPrice: 1.00
        outputTokenPrice: 1.00
        enabled: true

      - id: llama-3.1-sonar-small-128k-chat
        name: Sonar Small (Chat)
        description: Fast offline chat model
        maxContextWindow: 127072
        defaultMaxTokens: 2048
        maxMaxTokens: 4096
        inputTokenPrice: 0.20
        outputTokenPrice: 0.20
        enabled: true

    capabilities:
      supportsMultimodal: false
      supportsRAG: true
      supportsFunctionCalling: false
      supportsWebSearch: true
      supportsCitations: true

    authentication:
      apiKeyFormat: pplx-...
      apiKeyLabel: Perplexity API Key
      getApiKeyUrl: https://www.perplexity.ai/settings/api

    ui:
      icon: "üîç"
      order: 9

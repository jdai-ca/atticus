# Privacy & Data Protection Assessment

**Document Version:** 1.0.0  
**Last Updated:** October 21, 2025  
**Scope:** Comprehensive privacy analysis of Atticus AI legal and business advisory assistant

---

## Executive Summary

Atticus employs a **privacy-first architecture** where user data is stored locally and transmitted only to user-selected third-party AI providers. The application itself collects no telemetry, maintains no cloud infrastructure, and implements strong data isolation principles. However, privacy risks exist at the third-party provider level, requiring users to understand data flows and make informed choices.

**Privacy Model:** Local-First with User-Controlled Third-Party Integration

**Key Findings:**

- âœ… **Strong:** Local data storage, no telemetry, user data ownership
- âš ï¸ **Moderate:** Third-party AI provider data exposure, API key security
- âŒ **Weak:** Limited user guidance on data sensitivity classification

**Overall Privacy Rating:** 7.5/10 (Strong with Third-Party Dependencies)

---

## 1. Data Collection & Storage

### 1.1 Data Collected by Atticus Application

#### **Personal Data**

| Data Type              | Purpose                                | Storage Location                     | Retention                            |
| ---------------------- | -------------------------------------- | ------------------------------------ | ------------------------------------ |
| Conversation history   | User chat sessions                     | Local device (Electron storage)      | User-controlled (can delete anytime) |
| API keys               | Third-party AI provider authentication | Local device (encrypted OS keychain) | User-controlled                      |
| Provider configuration | User's AI provider settings            | Local device (JSON config file)      | User-controlled                      |
| Model preferences      | User's selected AI models              | Local device (JSON config file)      | User-controlled                      |
| Jurisdiction selection | User's applicable legal framework      | Local device (conversation metadata) | User-controlled                      |
| Practice area usage    | Detected legal/advisory areas          | Local device (conversation metadata) | User-controlled                      |

**No Personally Identifiable Information (PII) is required to use Atticus.**

#### **Non-Personal Data**

- Application version (local only, not transmitted)
- Configuration file versions (local only)
- Practice area keywords (bundled with application)
- Provider templates (bundled with application)

#### **Data NOT Collected**

- âŒ No analytics or telemetry
- âŒ No usage statistics
- âŒ No crash reports (unless manually submitted by user)
- âŒ No geolocation data
- âŒ No device fingerprinting
- âŒ No tracking cookies or identifiers
- âŒ No email addresses or contact information
- âŒ No payment information (users pay providers directly)
- âŒ No user accounts or authentication

---

### 1.2 Local Storage Architecture

**Storage Mechanism:** Electron's secure storage APIs

- Windows: Encrypted credentials via Windows Credential Manager
- macOS: Encrypted keychain via Keychain Services
- Linux: Encrypted via Secret Service API (libsecret)

**Storage Locations:**

```
User Data Directory (OS-specific):
  Windows: C:\Users\{username}\AppData\Roaming\Atticus\
  macOS: ~/Library/Application Support/Atticus/
  Linux: ~/.config/Atticus/

Stored Files:
  - config.json (provider settings, not API keys)
  - conversations/*.json (chat history)
  - cache/ (temporary YAML config caching)
```

**Encryption:**

- **At Rest:** OS-level encryption (Windows BitLocker, macOS FileVault, Linux LUKS)
- **API Keys:** Encrypted via OS secure storage (not in plain text config files)
- **Conversations:** Stored in plain JSON (no application-level encryption)

**Security Considerations:**

- âœ… API keys stored separately from config files
- âœ… OS-level access controls apply
- âš ï¸ Conversation data not encrypted at application level (relies on OS encryption)
- âš ï¸ Temporary API key storage in config (\_tempApiKey field) for backward compatibility

---

### 1.3 Data Transmission

**Destinations:** User-selected third-party AI providers only

**Transmission Method:**

- Direct HTTPS API calls from Electron main process
- TLS 1.2+ encryption (provider-dependent)
- No proxy or intermediary servers

**Data Transmitted to AI Providers:**

- User's conversation messages (prompt text)
- System prompts (practice area context, instructions)
- Conversation history (for context in multi-turn conversations)
- API authentication credentials (user's API key)

**Data NOT Transmitted:**

- âŒ No data sent to Atticus developers or servers (none exist)
- âŒ No data sent to analytics services
- âŒ No data sent to crash reporting services
- âŒ No data sent to third parties except user-chosen AI provider

**Network Architecture:**

```
User Device (Atticus)
        â†“ HTTPS (user's API key)
Third-Party AI Provider (OpenAI, Anthropic, etc.)
        â†“ AI Provider's internal processing
AI Provider's servers/data centers
```

**No Atticus-controlled servers exist in this data flow.**

---

## 2. Third-Party Data Sharing

### 2.1 AI Provider Data Exposure

**Critical Privacy Consideration:** When users submit queries to AI providers, those providers receive and process user data according to their own privacy policies.

#### **Provider Privacy Policies** (as of October 2025)

| Provider         | Data Retention                      | Training on User Data                     | Privacy Policy                             |
| ---------------- | ----------------------------------- | ----------------------------------------- | ------------------------------------------ |
| OpenAI           | 30 days (API); opt-out available    | No (API default); opt-in for improvements | https://openai.com/policies/privacy-policy |
| Anthropic Claude | Not used for training (API default) | No (contractual commitment)               | https://www.anthropic.com/privacy          |
| Google Gemini    | Not used for training (API)         | No for enterprise APIs                    | https://policies.google.com/privacy        |
| Azure OpenAI     | Customer controls retention         | No (Microsoft commitment)                 | https://privacy.microsoft.com/             |
| xAI Grok         | 30 days minimum                     | Not disclosed                             | https://x.ai/legal/privacy-policy          |
| Mistral AI       | Not used for training               | No (European privacy focus)               | https://mistral.ai/terms/                  |
| Cohere           | Not used for training (API)         | No (explicit policy)                      | https://cohere.com/privacy                 |
| Groq             | Not disclosed                       | Not disclosed                             | https://groq.com/privacy-policy/           |
| Perplexity AI    | Not disclosed                       | Not disclosed                             | https://www.perplexity.ai/privacy          |

**User Responsibility:** Users must review and accept each provider's privacy policy independently.

**Atticus Limitation:** Cannot enforce or guarantee third-party privacy practices.

---

### 2.2 Data Minimization Recommendations

**What Users Should NOT Input:**

- âŒ Social Security Numbers (SSN) or Tax IDs
- âŒ Credit card numbers or financial account details
- âŒ Passwords or authentication credentials
- âŒ Attorney-client privileged communications
- âŒ Confidential trade secrets or proprietary formulas
- âŒ Personal health information (PHI)
- âŒ Sensitive personal identifiers (passport numbers, etc.)
- âŒ Non-public material business information (pre-IPO financials, etc.)

**Safe to Input:**

- âœ… General legal/business questions
- âœ… Hypothetical scenarios
- âœ… Public legal concepts and frameworks
- âœ… General business strategy questions
- âœ… Anonymized or generalized situations
- âœ… Educational inquiries

**Best Practice:** Treat Atticus conversations as if discussing with a knowledgeable acquaintance in a coffee shopâ€”informative but not confidential.

---

### 2.3 Cross-Border Data Transfers

**AI Provider Server Locations:**

- **OpenAI:** Primarily US (Microsoft Azure); EU regions available
- **Anthropic:** Primarily US (AWS, GCP)
- **Google Gemini:** Global (user can specify region for some services)
- **Azure OpenAI:** User-controlled region selection
- **xAI:** Primarily US
- **Mistral AI:** Europe (EU-based company)
- **Cohere:** North America
- **Groq:** US
- **Perplexity:** US

**Privacy Shield Considerations:**

- EU-US Data Privacy Framework (replacement for Privacy Shield)
- Standard Contractual Clauses (SCCs) for GDPR compliance
- Users in EU/UK/Canada may have enhanced protections

**User Implications:**

- Users subject to GDPR, PIPEDA, or other data localization laws must select compliant providers
- Atticus does not enforce jurisdictional data residency
- Users responsible for compliance with applicable data protection laws

---

## 3. Regulatory Compliance Analysis

### 3.1 GDPR (EU General Data Protection Regulation)

**Applicability:** Atticus users in EU/EEA; EU citizens worldwide

#### **GDPR Principles Compliance:**

| Principle                              | Atticus Compliance | Notes                                                 |
| -------------------------------------- | ------------------ | ----------------------------------------------------- |
| **Lawfulness, Fairness, Transparency** | âœ… Strong          | Clear privacy notice; no hidden data collection       |
| **Purpose Limitation**                 | âœ… Strong          | Data used only for AI conversation functionality      |
| **Data Minimization**                  | âœ… Strong          | Collects only essential data; no accounts required    |
| **Accuracy**                           | âœ… N/A             | User-generated content; user controls accuracy        |
| **Storage Limitation**                 | âœ… Strong          | User controls retention; can delete anytime           |
| **Integrity & Confidentiality**        | âš ï¸ Moderate        | Local storage secure; third-party exposure exists     |
| **Accountability**                     | âš ï¸ Moderate        | Local architecture limits data controller obligations |

#### **GDPR Rights Enablement:**

- âœ… **Right to Access:** Users have direct file system access to all data
- âœ… **Right to Rectification:** Users can edit/delete conversations
- âœ… **Right to Erasure:** Users can delete all data locally
- âœ… **Right to Data Portability:** Conversations stored in standard JSON
- âœ… **Right to Restriction:** Users control what data is sent to providers
- âœ… **Right to Object:** Users choose whether to use application
- âš ï¸ **Right to Automated Decision-Making Protection:** AI outputs are advisory only; users make decisions

**Data Controller Status:**

- **Atticus Application:** Not a data controller (no data collection by developers)
- **User (Individual):** May be data controller for their own conversations
- **AI Providers:** Data controllers/processors for transmitted data

**GDPR Compliance Rating:** HIGH for local data; DELEGATED to third parties for transmitted data

---

### 3.2 CCPA (California Consumer Privacy Act)

**Applicability:** California residents using Atticus

#### **CCPA Rights Compliance:**

| Right                           | Atticus Compliance | Implementation                                     |
| ------------------------------- | ------------------ | -------------------------------------------------- |
| **Right to Know**               | âœ… Full            | This document discloses all data practices         |
| **Right to Delete**             | âœ… Full            | Users can delete local data anytime                |
| **Right to Opt-Out of Sale**    | âœ… N/A             | No data sale; no data collection by Atticus        |
| **Right to Non-Discrimination** | âœ… Full            | No differential treatment based on privacy choices |

**Personal Information Sold or Shared:** NONE

**CCPA Compliance Rating:** FULL COMPLIANCE (no business-to-consumer data practices)

---

### 3.3 PIPEDA (Canada Personal Information Protection)

**Applicability:** Canadian users; Canadian business operations

#### **PIPEDA Principles Compliance:**

| Principle                               | Compliance   | Notes                                        |
| --------------------------------------- | ------------ | -------------------------------------------- |
| **Accountability**                      | âš ï¸ Limited   | No organization controls user data           |
| **Identifying Purposes**                | âœ… Strong    | Purpose clearly communicated                 |
| **Consent**                             | âœ… Strong    | Users consent by choosing to use application |
| **Limiting Collection**                 | âœ… Strong    | Minimal data collection                      |
| **Limiting Use, Disclosure, Retention** | âœ… Strong    | User-controlled                              |
| **Accuracy**                            | âœ… N/A       | User-generated                               |
| **Safeguards**                          | âš ï¸ Moderate  | OS-level security; user responsibility       |
| **Openness**                            | âœ… Strong    | Full transparency via this document          |
| **Individual Access**                   | âœ… Strong    | Direct file access                           |
| **Challenging Compliance**              | âœ… Available | GitHub issue tracker for concerns            |

**PIPEDA Compliance Rating:** HIGH with reliance on user self-management

---

### 3.4 UK GDPR & Data Protection Act 2018

**Post-Brexit Status:** UK GDPR largely mirrors EU GDPR

**Compliance:** Same as EU GDPR (Section 3.1)

**ICO Registration:** Not required (no data processing by organization)

---

### 3.5 Other Jurisdictions

- **Australia (Privacy Act 1988):** Compliant (no Australian entity data handling)
- **Brazil (LGPD):** Compliant (local-first architecture aligns with principles)
- **Japan (APPI):** Compliant (no cross-border data transfer by Atticus)
- **Singapore (PDPA):** Compliant (user-controlled data management)

**General Principle:** Local-first architecture minimizes regulatory obligations across jurisdictions.

---

## 4. Privacy Risks & Vulnerabilities

### 4.1 Critical Privacy Risks

#### **Risk 1: Third-Party AI Provider Data Retention**

**Description:** Users may not understand that AI providers receive and may retain conversation data.

**Likelihood:** HIGH  
**Impact:** HIGH (privacy expectations violated)

**Mitigation:**

- âš ï¸ Current: Settings dialog mentions "API calls are made directly to the providers"
- âŒ Missing: Prominent warning when first submitting query
- âŒ Missing: Provider-specific privacy ratings/indicators

**Recommendation:**

- Implement first-use privacy notice with provider data flow diagram
- Display provider privacy policy links in Settings
- Add privacy rating system (5-star scale) for each provider
- Warning banner for queries containing potential PII

---

#### **Risk 2: Inadvertent PII Disclosure**

**Description:** Users may input sensitive personal information without realizing privacy implications.

**Likelihood:** MEDIUM  
**Impact:** HIGH (identity theft, confidentiality breach)

**Mitigation:**

- âœ… **MANDATORY PII Scanner** - Always-on detection of 29+ sensitive data types
- âœ… **Jurisdiction-Aware** - Scans for region-specific identifiers (CA, US, MX, EU, UK)
- âœ… **Complete Audit Trail** - All scans logged with user decisions for legal protection
- âœ… **Cannot Be Disabled** - Scanner runs on every message to prevent liability gaps
- âœ… Documentation warns against sensitive data input

**Implemented Protection (October 2025):**

The PII Scanner is now a **mandatory, always-enabled security feature** that:

- Detects 29 types of sensitive information before transmission
- Warns users with risk levels (Critical/High/Moderate/Low)
- Provides options: Proceed, Cancel, or Anonymize
- Maintains complete audit log accessible via Shield button
- Protects Atticus from liability by proving users were warned

**Scanner cannot be disabled** - This is intentional for legal protection.

---

#### **Risk 3: Device Compromise Leading to Data Access**

**Description:** If user's device is compromised, all local data (conversations, API keys) is accessible.

**Likelihood:** LOW  
**Impact:** HIGH (full conversation history exposure)

**Mitigation:**

- âœ… OS-level encryption for API keys
- âš ï¸ Conversation data not encrypted at application level
- âŒ No additional authentication layer

**Recommendation:**

- Implement application-level encryption for conversations (optional)
- Add master password option for sensitive data protection
- Auto-lock feature after inactivity period
- Secure delete (overwrite, not just unlink)

---

#### **Risk 4: API Key Exposure**

**Description:** API keys stored locally could be extracted by malware or physical access.

**Likelihood:** MEDIUM  
**Impact:** HIGH (unauthorized API usage, cost, data access)

**Mitigation:**

- âœ… Encrypted OS keychain storage
- âš ï¸ Temporary \_tempApiKey field in config for backward compatibility
- âŒ No rate limiting or usage alerts

**Recommendation:**

- Remove \_tempApiKey temporary storage mechanism
- Implement API key rotation reminders
- Usage monitoring and alerts (optional)
- Provider-side rate limiting reliance

---

#### **Risk 5: Conversation Data Leakage via Backups**

**Description:** User backups (cloud, external drive) may expose conversation data.

**Likelihood:** MEDIUM  
**Impact:** MEDIUM (unintended data persistence)

**Mitigation:**

- âŒ No backup encryption enforcement
- âŒ No user guidance on backup privacy

**Recommendation:**

- Documentation on backup privacy considerations
- Option to exclude Atticus data from system backups
- Encrypted backup option within application
- Reminder to secure delete when decommissioning devices

---

### 4.2 Moderate Privacy Risks

#### **Risk 6: Model Training on User Data (Provider-Dependent)**

**Likelihood:** LOW (most providers opt-out by default for API)  
**Impact:** MEDIUM (privacy violation, competitive intelligence leak)

**Mitigation:** User must review provider policies; some providers (Anthropic, Cohere) contractually prohibit training on API data.

---

#### **Risk 7: Conversation Context Accumulation**

**Likelihood:** HIGH (feature by design)  
**Impact:** LOW-MEDIUM (more data shared with provider over time)

**Mitigation:** Users can start new conversations; old context not shared.

**Recommendation:** Add "Clear Context" button to reset conversation without deleting history.

---

#### **Risk 8: Metadata Leakage**

**Likelihood:** MEDIUM  
**Impact:** LOW (patterns revealed even if content protected)

**Mitigation:** Limited metadata collected; timestamps and practice areas stored locally.

**Recommendation:** Option to disable practice area tracking for extra privacy.

---

### 4.3 Low Privacy Risks

#### **Risk 9: Supply Chain Compromise**

**Likelihood:** LOW  
**Impact:** HIGH if occurs

**Mitigation:** Open source code allows audit; npm package integrity checks; signed releases.

---

#### **Risk 10: Phishing/Social Engineering**

**Likelihood:** LOW  
**Impact:** MEDIUM

**Mitigation:** No login or authentication reduces phishing surface; users must protect API keys.

---

## 5. Privacy-Enhancing Features

### 5.1 Implemented Privacy Features

âœ… **Local-First Architecture**

- All data stored on user's device by default
- No cloud synchronization or backup (user-controlled only)

âœ… **No User Accounts**

- No registration, login, or authentication required
- No email or personal information collected

âœ… **No Telemetry**

- Zero analytics, tracking, or usage statistics
- No crash reporting (unless manually submitted)

âœ… **Direct API Integration**

- No intermediary servers capturing data
- User's API key authenticates directly with provider

âœ… **Complete User Control**

- Delete conversations anytime
- Export data in standard JSON format
- No vendor lock-in

âœ… **Multi-Provider Choice**

- Users select provider based on privacy preferences
- Can switch providers without data migration

âœ… **Open Source Transparency**

- Full code audit possible (Apache 2.0 license)
- Community security review enabled

âœ… **Secure API Key Storage**

- OS-level encrypted keychains
- Keys not stored in plain text configuration

âœ… **Mandatory PII Scanner (Implemented October 2025)**

- **Always-enabled** client-side detection of 29+ PII types
- Jurisdiction-aware scanning (CA, US, MX, EU, UK)
- Warning before sending potentially sensitive data
- Complete audit trail with user decisions
- **Cannot be disabled** for legal protection

---

### 5.2 Planned Privacy Enhancements

#### **Short-Term (0-6 months)**

ðŸ”„ **Provider Privacy Ratings**

- 5-star privacy rating for each provider
- Based on: data retention, training policies, jurisdiction, audit history

ðŸ”„ **First-Use Privacy Notice**

- Comprehensive data flow explanation
- Require acknowledgment before first query

ðŸ”„ **Data Classification Guide**

- In-app help on what data is safe to input
- Examples of sensitive data to avoid

#### **Medium-Term (6-12 months)**

ðŸ”„ **Application-Level Encryption**

- Optional master password for conversation encryption
- Local encryption before OS-level encryption

ðŸ”„ **Anonymization Layer**

- Optional entity redaction (replace names, companies with placeholders)
- Reversible locally; providers see anonymized queries

ðŸ”„ **Usage Monitoring**

- Optional API usage tracking (local only)
- Cost alerts and budget limits

ðŸ”„ **Secure Delete**

- Overwrite data on deletion (not just unlink)
- DOD 5220.22-M or similar standard

#### **Long-Term (1-2 years)**

ðŸ”„ **On-Premise Model Support**

- Integration with locally-hosted LLMs (Llama, Mistral local)
- Zero third-party data sharing option

ðŸ”„ **End-to-End Encryption**

- Encrypted conversations with E2EE keys
- Provider-agnostic encryption layer

ðŸ”„ **Privacy-Preserving Analytics**

- Differential privacy techniques for opt-in usage statistics
- Aggregate insights without individual tracking

---

## 6. User Privacy Best Practices

### 6.1 Before Using Atticus

1. **Review AI Provider Privacy Policies**

   - Understand data retention periods
   - Check if data is used for model training
   - Verify jurisdictional compliance (GDPR, CCPA, etc.)

2. **Enable Device Encryption**

   - Windows: BitLocker
   - macOS: FileVault
   - Linux: LUKS

3. **Secure Your Device**

   - Strong password/PIN
   - Keep OS and security software updated
   - Firewall enabled

4. **Understand Data Flows**
   - Local storage: Your device
   - Transmitted data: AI provider's servers
   - No Atticus cloud infrastructure

---

### 6.2 During Use

1. **Classify Data Before Input**

   - Public/General: Safe to input
   - Confidential: Avoid or anonymize
   - Privileged/Secret: Never input

2. **Anonymize When Possible**

   - Replace real names with "Client A", "Company B"
   - Generalize specific details ("a tech startup" vs. "Acme Inc.")
   - Remove identifying numbers (addresses, phone, SSN)

3. **Use Separate Conversations for Sensitive Topics**

   - Limit context sharing across different matters
   - Delete sensitive conversations promptly after use

4. **Choose Privacy-Focused Providers**

   - Anthropic Claude (strong privacy commitment)
   - Mistral AI (EU-based, GDPR-native)
   - Azure OpenAI (enterprise controls)

5. **Avoid Free-Tier Providers for Sensitive Queries**
   - Free tiers may have different privacy policies
   - Paid API tiers often have stronger privacy guarantees

---

### 6.3 After Use

1. **Regularly Review Stored Conversations**

   - Delete conversations containing sensitive information
   - Export important conversations to secure backup

2. **Rotate API Keys Periodically**

   - Change provider API keys every 90 days
   - Immediately rotate if compromise suspected

3. **Monitor API Usage**

   - Check provider dashboards for unexpected activity
   - Verify charges match your usage

4. **Secure Backups**

   - Encrypt backups containing Atticus data
   - Exclude Atticus folder from cloud backups if desired

5. **Decommissioning Devices**
   - Securely wipe Atticus data before disposal
   - Revoke API keys used on old device

---

## 7. Privacy by Design Assessment

### 7.1 Privacy by Design Principles (Cavoukian)

#### **1. Proactive not Reactive; Preventative not Remedial** âœ…

**Evidence:** Privacy considered from architecture phase; local-first design prevents data collection issues before they occur.

**Score:** STRONG

---

#### **2. Privacy as the Default Setting** âœ…

**Evidence:** No data collection by default; no opt-out required because there's no opt-in.

**Score:** EXCELLENT

---

#### **3. Privacy Embedded into Design** âœ…

**Evidence:** Local storage is architectural foundation, not added feature; no cloud infrastructure exists.

**Score:** EXCELLENT

---

#### **4. Full Functionality â€“ Positive-Sum, not Zero-Sum** âœ…

**Evidence:** Privacy does not compromise core features; users get AI assistance without cloud dependency.

**Score:** STRONG

---

#### **5. End-to-End Security â€“ Full Lifecycle Protection** âš ï¸

**Evidence:**

- Strong: Secure creation (OS keychain for API keys)
- Moderate: Secure storage (local files, OS encryption-dependent)
- Weak: Secure transmission (relies on provider TLS)
- Moderate: Secure deletion (standard file deletion, not overwrite)

**Score:** MODERATE (improvements needed in transmission security and secure deletion)

---

#### **6. Visibility and Transparency â€“ Keep it Open** âš ï¸

**Evidence:**

- Strong: Open source code
- Strong: Clear documentation of data flows
- Weak: No real-time visibility into what data is sent to providers
- Weak: No audit logs of API calls

**Score:** MODERATE (transparency exists but could be enhanced)

---

#### **7. Respect for User Privacy â€“ Keep it User-Centric** âœ…

**Evidence:**

- Complete user control over data
- No forced data sharing
- User chooses providers and models
- Easy deletion and export

**Score:** EXCELLENT

**Overall Privacy by Design Score:** 8.5/10 (Strong with room for improvement in security and transparency)

---

## 8. Privacy Comparison: Atticus vs. Alternatives

### 8.1 Competitive Privacy Analysis

| Feature                    | Atticus        | ChatGPT Plus        | Claude.ai           | LexisNexis/Westlaw AI | Clio AI             |
| -------------------------- | -------------- | ------------------- | ------------------- | --------------------- | ------------------- |
| **Local Storage**          | âœ… Yes         | âŒ Cloud            | âŒ Cloud            | âŒ Cloud              | âŒ Cloud            |
| **User Data Ownership**    | âœ… Full        | âš ï¸ Partial          | âš ï¸ Partial          | âš ï¸ Partial            | âš ï¸ Partial          |
| **Telemetry Collection**   | âŒ None        | âœ… Extensive        | âš ï¸ Some             | âœ… Extensive          | âœ… Extensive        |
| **Data Portability**       | âœ… Full (JSON) | âš ï¸ Export available | âš ï¸ Export available | âŒ Limited            | âš ï¸ Export available |
| **Provider Choice**        | âœ… 9 providers | âŒ OpenAI only      | âŒ Anthropic only   | âŒ Proprietary        | âŒ Proprietary      |
| **No Account Required**    | âœ… Yes         | âŒ Requires account | âŒ Requires account | âŒ Requires account   | âŒ Requires account |
| **Training Opt-Out**       | âœ… N/A (local) | âœ… Available        | âœ… Default          | âš ï¸ Unclear            | âš ï¸ Unclear          |
| **GDPR Compliance**        | âœ… Strong      | âœ… Compliant        | âœ… Compliant        | âœ… Compliant          | âœ… Compliant        |
| **Data Residency Control** | âœ… User device | âŒ No control       | âŒ No control       | âš ï¸ Some control       | âŒ No control       |
| **End-to-End Encryption**  | âš ï¸ OS-level    | âš ï¸ In transit       | âš ï¸ In transit       | âœ… Yes                | âš ï¸ In transit       |

**Privacy Advantage:** Atticus offers superior privacy through local-first architecture and zero data collection by developers.

**Privacy Trade-off:** Users must manage their own data security; no cloud backup or cross-device sync.

---

## 9. Privacy Incident Response

### 9.1 Incident Categories

**Type 1: Data Breach (Atticus Application)**

- Likelihood: VERY LOW (no centralized data storage)
- Response: Not applicable (no data to breach)

**Type 2: Device Compromise**

- Likelihood: LOW-MEDIUM (user device security-dependent)
- Response: User-managed; recommend API key rotation and conversation deletion

**Type 3: Third-Party Provider Breach**

- Likelihood: LOW (major providers have strong security)
- Response: Monitor provider security notices; rotate API keys if advised

**Type 4: Supply Chain Compromise**

- Likelihood: LOW (open source, signed releases)
- Response: Immediate release of patched version; public disclosure

---

### 9.2 User Incident Response Procedures

**If You Suspect Device Compromise:**

1. Immediately disconnect device from network
2. Rotate all API keys from a secure device
3. Review API provider usage logs for unauthorized activity
4. Scan device for malware
5. Change device passwords
6. Consider secure delete and reinstall of Atticus
7. Report to API providers if fraudulent usage detected

**If Third-Party Provider Has Data Breach:**

1. Check provider's security advisory for impact assessment
2. Determine if your conversations were affected
3. Rotate API keys as precautionary measure
4. Review conversation history for sensitive data exposure
5. Consider deleting affected conversations
6. Follow provider's recommended remediation steps

**If You Accidentally Shared Sensitive Data:**

1. Delete conversation locally immediately
2. Contact AI provider to request data deletion (per their policy)
3. Change any credentials or secrets mentioned in conversation
4. Assess business impact and notify affected parties if required
5. Review data classification practices to prevent recurrence

---

### 9.3 Developer Incident Response

**If Critical Privacy Vulnerability Discovered:**

1. Immediate assessment of impact and affected versions
2. Development of patch within 24-48 hours
3. Coordinated disclosure (90-day timeline for responsible disclosure)
4. Public advisory on GitHub repository
5. Notification via release notes and security mailing list (if established)
6. Post-incident review and prevention measures

**If Supply Chain Compromise:**

1. Immediate investigation and confirmation
2. Revocation of compromised packages/releases
3. Public disclosure within 24 hours
4. Clean build and release of patched version
5. Cooperation with security researchers and authorities
6. Enhanced supply chain security measures

---

## 10. Privacy Governance

### 10.1 Privacy Roles & Responsibilities

| Role                      | Responsibility                                                                                    |
| ------------------------- | ------------------------------------------------------------------------------------------------- |
| **User**                  | Protect device, manage API keys, classify data sensitivity, choose providers                      |
| **Atticus Developers**    | Maintain local-first architecture, document data flows, patch vulnerabilities, no data collection |
| **AI Providers**          | Secure data transmission/storage, honor privacy policies, comply with regulations                 |
| **Open Source Community** | Security audits, vulnerability disclosure, privacy improvement suggestions                        |

**No Chief Privacy Officer:** Not applicable (no organizational data processing)

**Privacy Accountability:** Distributed to users and third-party providers

---

### 10.2 Privacy Review Cycle

- **Continuous:** Monitor third-party provider privacy policy changes
- **Quarterly:** Review privacy documentation for accuracy
- **Annually:** Comprehensive privacy assessment update
- **Upon Material Change:** Feature additions affecting data flows

---

### 10.3 Privacy Contact

**For Privacy Questions or Concerns:**

- GitHub Repository: https://github.com/{organization}/atticus (Issues tagged "privacy")
- Security Vulnerabilities: security@{domain}.{tld} (if established)
- Community: Discussions tab on GitHub

**No Dedicated Privacy Officer** (local-first architecture minimizes organizational privacy role)

---

## 11. Privacy Metrics

### 11.1 Privacy KPIs

| Metric                               | Target            | Current Status          |
| ------------------------------------ | ----------------- | ----------------------- |
| Data collection by application       | 0 items           | âœ… 0 items              |
| Telemetry/analytics events           | 0 events          | âœ… 0 events             |
| Privacy policy violations (reported) | 0 per year        | âœ… 0 (no reports)       |
| Local storage encryption             | 100% of API keys  | âœ… 100% (OS keychain)   |
| User data export capability          | 100% of data      | âœ… 100% (JSON files)    |
| Third-party data sharing disclosures | 100% transparency | âœ… 100% (documented)    |
| Privacy documentation accuracy       | 100% current      | âœ… 100% (this document) |

### 11.2 User Privacy Awareness

**Desired Outcomes:**

- > 90% of users understand data flows (local vs. third-party)
- > 80% of users review provider privacy policies before first use
- > 70% of users practice data classification (what not to input)
- <5% of users inadvertently share PII in conversations

**Current Measurement:** Not tracked (no telemetry)

**Alternative:** User surveys, community feedback, GitHub discussions

---

## 12. Regulatory Horizon Scanning

### 12.1 Emerging Privacy Regulations

**EU AI Act (2024)**

- **Impact:** May require privacy disclosures for AI systems
- **Atticus Position:** Local-first architecture aligns with privacy goals
- **Action Required:** Monitor final implementation; ensure compliance

**US State Privacy Laws (expanding)**

- **Impact:** More states adopting CCPA-like laws
- **Atticus Position:** Already CCPA-compliant; new laws unlikely to affect
- **Action Required:** Ongoing monitoring

**Data Localization Requirements**

- **Impact:** Some countries requiring data storage within borders
- **Atticus Position:** Local storage satisfies most requirements
- **Action Required:** Document data residency for user compliance

**AI Privacy Standards**

- **Impact:** Industry standards emerging (ISO, IEEE, NIST)
- **Atticus Position:** Opportunity to lead by example
- **Action Required:** Participate in standards development

---

## 13. Privacy Recommendations

### 13.1 For Users

**High Priority:**

1. Enable device encryption (BitLocker, FileVault, LUKS)
2. Review AI provider privacy policies before use
3. Never input confidential, privileged, or highly sensitive data
4. Rotate API keys every 90 days
5. Delete old conversations containing business-sensitive information

**Medium Priority:**

1. Use separate conversations for different clients/matters
2. Choose privacy-focused providers (Anthropic, Mistral, Azure)
3. Anonymize names and identifying details when possible
4. Monitor API usage for unauthorized access
5. Secure backups containing Atticus data

**Low Priority:**

1. Export conversations for secure archival
2. Practice "need to share" principle (minimize context)
3. Disable system backups of Atticus folder (if desired)

---

### 13.2 For Developers

**Completed (October 2025):**

âœ… **PII Scanner Implementation**

- 29+ detection patterns with jurisdiction support
- Mandatory scanning (cannot be disabled)
- Complete audit trail with user decisions
- Legal protection through tamper-evident logging

**Immediate (0-3 months):**

1. Add provider privacy ratings to Settings
2. Create first-use privacy notice
3. Remove \_tempApiKey temporary storage
4. Add data classification guide to Help

**Short-Term (3-9 months):**

1. Application-level conversation encryption (optional)
2. Anonymization layer (entity redaction)
3. Secure delete (overwrite)
4. Privacy-preserving usage monitoring (opt-in)
5. Master password protection

**Long-Term (9-24 months):**

1. On-premise model integration (zero third-party sharing)
2. End-to-end encryption for cloud sync (optional feature)
3. Differential privacy for analytics (if implemented)
4. Privacy certification (ISO 27001, SOC 2, etc.)

---

## 14. Conclusion

Atticus achieves **strong privacy posture** through architectural choices that eliminate centralized data collection, storage, and processing. The local-first design inherently protects user privacy better than cloud-based alternatives. However, users must understand that third-party AI provider integration introduces unavoidable privacy considerations.

### Privacy Strengths:

- âœ… No data collection by Atticus developers
- âœ… Local storage and user ownership
- âœ… No telemetry or tracking
- âœ… Multi-provider choice enables privacy preferences
- âœ… Open source transparency
- âœ… Strong regulatory compliance (GDPR, CCPA, PIPEDA)

### Privacy Weaknesses:

- âš ï¸ Third-party AI provider data exposure
- âš ï¸ Limited user guidance on data sensitivity
- âš ï¸ No application-level encryption (relies on OS)
- âš ï¸ API key security depends on OS implementation
- âš ï¸ Users may not understand privacy implications

### Privacy Commitment:

**Atticus will never:**

- Collect user data for developer purposes
- Implement telemetry without explicit opt-in
- Share user data with third parties (except user-chosen AI providers)
- Require user accounts or authentication
- Implement dark patterns to coerce data sharing
- Prioritize features over privacy protection

**Atticus will always:**

- Maintain local-first architecture
- Provide full transparency about data flows
- Give users complete control over their data
- Comply with applicable privacy regulations
- Enhance privacy protections over time
- Respect user autonomy and informed consent

**Privacy is not a feature to be addedâ€”it is a principle embedded in Atticus's architecture from inception.**

---

## 15. Privacy Policy (User-Facing)

**Effective Date:** October 21, 2025

### What Data We Collect

We collect **no data**. Atticus operates entirely on your local device. We do not have servers, databases, or analytics infrastructure.

### What Data You Generate

You create conversations stored on your device. This data is yours and never transmitted to us.

### What Data Third Parties Receive

When you use Atticus, you send queries to AI providers you select (OpenAI, Anthropic, etc.). Those providers receive your conversation data per their privacy policies. Review each provider's policy before use.

### Your Rights

- **Access:** Direct file system access to all your data
- **Delete:** Delete conversations anytime from application
- **Export:** Conversations stored in standard JSON format
- **Control:** You choose which providers receive your data

### Children's Privacy

Atticus does not collect data from anyone, including children under 13. Parents should supervise use.

### Changes to Privacy Policy

Material changes will be announced via application release notes and GitHub repository.

### Contact

Questions or concerns: GitHub repository issues tagged "privacy"

---

## Document Control

| Version | Date       | Author                   | Changes                                  |
| ------- | ---------- | ------------------------ | ---------------------------------------- |
| 1.0.0   | 2025-10-21 | Atticus Development Team | Initial comprehensive privacy assessment |

**Review Cycle:** Annually or upon material change to architecture, features, or regulations

**Distribution:** Public (included in product repository)

**Feedback:** Submit privacy concerns via GitHub repository

---

**END OF DOCUMENT**
